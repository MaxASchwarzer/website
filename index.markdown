---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
list_title: ' '
title: 'About Me'
margin: 1in
---

I'm a final-year PhD student at Mila, working with Aaron Courville and Marc Bellemare, at the intersection of scaling and sample-efficient reinforcement learning. My work has focused on allowing agents to learn as efficiently or more than humans, and I'm excited about the pathway that today's ultra-capable large models have opened up towards revolutionarily-efficient agents that one day will transform humanity's relationship with the physical world.

## News

- **June 2023** I'm moving back to California to start an internship in Samy Bengio's machine learning research group at Apple. See you all in the Bay!
- **June 2023**: I'm thrilled to announce that our new paper "Bigger, Better, Faster: Human-level Atari with human-level efficiency," to ICML 2023. Reaching human-level sample-efficiency with pure model-free reinforcement learning on Atari 100k allows me to finally end my love-hate relationship with this benchmark and move on to a new phase in life.
- **June 2023**: Sadly, my time as a Student Researcher at Google Brain (now Google DeepMind) has come to an end. It's been an incredible journey, and I'm grateful for the wonderful community at Google Montreal, inside and outside of research.
- **February 2023**: We've had two papers accepted at ICLR 2023! Our work _Sample Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier_, on a new approach to scaling model-free RL, received a top 5% award, and our paper _Simplicial Embeddings in Self-Supervised Learning and Downstream Classification_ received a top 25% award. Thanks to all of my coauthors!
- **September 2022**: Our paper, "Beyond Tabula Rasa: Reincarnating Reinforcement Learning," has been accepted at NeurIPS 2022. This work highlights the importance of efficient retraining in reinforcement learning, mitigating the massive computational requirements of the field and allowing for 
- **June 2022**: I'm honored to have received the Borealis AI Fellowship this year. It's awarded to ten promising Canadian AI PhD students, and I'm humbled to be among them.
- **May 2022**: I'm excited to share that I've received the FRQNT PhD Scholarship, a full fellowship awarded to promising PhD students studying science and technology in Qu√©bec.
- **May 2022**: I'm happy to announce that our paper, "The Primacy Bias in Deep Reinforcement Learning," will be published at ICML 2022. This work presents a novel and highly unusual study into the pathologies of deep reinforcement learning, and suggests a set of unintuitive remedies (iterative resetting agents' parameters) may dramatically improve their performance and robustness.
- **December 2021**: I'm thrilled to share that our paper, "Deep Reinforcement Learning at the Statistical Precipice," received the Outstanding Paper Award at NeurIPS 2021. It's an honor to have our work recognized in this way, and I'm grateful to the community for this recognition.
- **September 2021**: Our papers _Pretraining Representations for Data-Efficient Reinforcement Learning_ and _Deep Reinforcement Learning at the Statistical Precipice_ have been accepted to NeurIPS 2021!
